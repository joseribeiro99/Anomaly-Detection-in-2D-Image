{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 images belonging to 1 classes.\n",
      "Found 15 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Size of our input images\n",
    "SIZE = 128\n",
    "\n",
    "#############################################################################\n",
    "#Define generators for training, validation and also anomaly data.\n",
    "\n",
    "batch_size = 64\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'dataset/train/',\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    'dataset/valid/',\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "anomaly_generator = datagen.flow_from_directory(\n",
    "    'dataset/anomaly/',\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 3)       1731      \n",
      "=================================================================\n",
      "Total params: 52,067\n",
      "Trainable params: 52,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the autoencoder. \n",
    "#Try to make the bottleneck layer size as small as possible to make it easy for\n",
    "#density calculations and also picking appropriate thresholds. \n",
    "\n",
    "#Encoder\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "#Decoder\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/7 [===>..........................] - ETA: 2s - loss: 0.1033 - mse: 0.1033WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7000 batches). You may need to use the repeat() function when building your dataset.\n",
      "7/7 [==============================] - 1s 27ms/step - loss: 0.1033 - mse: 0.1033 - val_loss: 0.1022 - val_mse: 0.1022\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fit the model. \n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch= 500 // batch_size,\n",
    "        epochs=1000,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=75 // batch_size,\n",
    "        shuffle = True)\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get all batches generated by the datagen and pick a batch for prediction\n",
    "#Just to test the model. \n",
    "data_batch = []  #Capture all training batches as a numpy array\n",
    "img_num = 0\n",
    "while img_num <= train_generator.batch_index:   #gets each generated batch of size batch_size\n",
    "    data = train_generator.next()\n",
    "    data_batch.append(data[0])\n",
    "    img_num = img_num + 1\n",
    "\n",
    "predicted = model.predict(data_batch[0])  #Predict on the first batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Sanity check, view few images and corresponding reconstructions\n",
    "image_number = random.randint(0, predicted.shape[0])\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(data_batch[0][image_number])\n",
    "plt.subplot(122)\n",
    "plt.imshow(predicted[image_number])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Let us examine the reconstruction error between our validation data (good/normal images)\n",
    "# and the anomaly images\n",
    "validation_error = model.evaluate_generator(validation_generator)\n",
    "anomaly_error = model.evaluate_generator(anomaly_generator)\n",
    "\n",
    "print(\"Recon. error for the validation (normal) data is: \", validation_error)\n",
    "print(\"Recon. error for the anomaly data is: \", anomaly_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Let us extract (or build) the encoder network, with trained weights.\n",
    "#This is used to get the compressed output (latent space) of the input image. \n",
    "#The compressed output is then used to calculate the KDE\n",
    "\n",
    "encoder_model = Sequential()\n",
    "encoder_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3), weights=model.layers[0].get_weights()) )\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.add(Conv2D(32, (3, 3), activation='relu', padding='same', weights=model.layers[2].get_weights()))\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', weights=model.layers[4].get_weights()))\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Calculate KDE using sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "#Get encoded output of input images = Latent space\n",
    "encoded_images = encoder_model.predict_generator(train_generator)\n",
    "\n",
    "# Flatten the encoder output because KDE from sklearn takes 1D vectors as input\n",
    "encoder_output_shape = encoder_model.output_shape #Here, we have 16x16x16\n",
    "out_vector_shape = encoder_output_shape[1]*encoder_output_shape[2]*encoder_output_shape[3]\n",
    "\n",
    "encoded_images_vector = [np.reshape(img, (out_vector_shape)) for img in encoded_images]\n",
    "\n",
    "#Fit KDE to the image latent data\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate density and reconstruction error to find their means values for\n",
    "#good and anomaly images. \n",
    "#We use these mean and sigma to set thresholds. \n",
    "def calc_density_and_recon_error(batch_images):\n",
    "    \n",
    "    density_list=[]\n",
    "    recon_error_list=[]\n",
    "    for im in range(0, batch_images.shape[0]-1):\n",
    "        \n",
    "        img  = batch_images[im]\n",
    "        img = img[np.newaxis, :,:,:]\n",
    "        encoded_img = encoder_model.predict([[img]]) # Create a compressed version of the image using the encoder\n",
    "        encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] # Flatten the compressed image\n",
    "        density = kde.score_samples(encoded_img)[0] # get a density score for the new image\n",
    "        reconstruction = model.predict([[img]])\n",
    "        reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "        density_list.append(density)\n",
    "        recon_error_list.append(reconstruction_error)\n",
    "        \n",
    "    average_density = np.mean(np.array(density_list))  \n",
    "    stdev_density = np.std(np.array(density_list)) \n",
    "    \n",
    "    average_recon_error = np.mean(np.array(recon_error_list))  \n",
    "    stdev_recon_error = np.std(np.array(recon_error_list)) \n",
    "    \n",
    "    return average_density, stdev_density, average_recon_error, stdev_recon_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Get average and std dev. of density and recon. error for uninfected and anomaly (parasited) images. \n",
    "#For this let us generate a batch of images for each. \n",
    "train_batch = train_generator.next()[0]\n",
    "anomaly_batch = anomaly_generator.next()[0]\n",
    "\n",
    "uninfected_values = calc_density_and_recon_error(train_batch)\n",
    "anomaly_values = calc_density_and_recon_error(anomaly_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Now, input unknown images and sort as Good or Anomaly\n",
    "def check_anomaly(img_path):\n",
    "    density_threshold = 2500 #Set this value based on the above exercise\n",
    "    reconstruction_error_threshold = 0.004 # Set this value based on the above exercise\n",
    "    img  = Image.open(img_path)\n",
    "    img = np.array(img.resize((128,128), Image.ANTIALIAS))\n",
    "    plt.imshow(img)\n",
    "    img = img / 255.\n",
    "    img = img[np.newaxis, :,:,:]\n",
    "    encoded_img = encoder_model.predict([[img]]) \n",
    "    encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] \n",
    "    density = kde.score_samples(encoded_img)[0] \n",
    "\n",
    "    reconstruction = model.predict([[img]])\n",
    "    reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "\n",
    "    if density < density_threshold or reconstruction_error > reconstruction_error_threshold:\n",
    "        print(\"The image is an anomaly\")\n",
    "        \n",
    "    else:\n",
    "        print(\"The image is NOT an anomaly\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load a couple of test images and verify whether they are reported as anomalies.\n",
    "import glob\n",
    "para_file_paths = glob.glob('cell_images2/parasitized/images/*')\n",
    "uninfected_file_paths = glob.glob('cell_images2/uninfected_train/images/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Anomaly image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(para_file_paths[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Good/normal image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(uninfected_file_paths[num])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('anomaly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "49d19fe7c950820851d5fd36f8ce63d405a6c371410d1dc9982820309bcd1f6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
